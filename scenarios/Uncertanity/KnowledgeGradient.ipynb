{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as spy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synth Example\n",
    "We want to use knowledge gradient to see if we can efficiently sample and learn the following noisy function. \n",
    "$$f(x) = 0.50 \\times x + \\mathcal{N}(0, 1)$$\n",
    "For the sake of this example, we assume that $x$ is constrained between $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define f(x)\n",
    "def f(x):\n",
    "    return 0.50*x + np.random.normal(0.0, 1.0)\n",
    "\n",
    "# Establish Bounds on x\n",
    "x_bounds = [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate \n",
    "For this example, given that we have a uniform noise level, we will contend with using a vanilla GP with RBF and White kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1) + GPy.kern.White(input_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will uniformly sample the solution space and fit the GP on that data. This enable us to get a lay of the land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_samples = 5\n",
    "\n",
    "# Generate random samples\n",
    "X = np.random.random_sample(initial_samples)\n",
    "Y = np.zeros(initial_samples)\n",
    "for idx, i in enumerate(X):\n",
    "    Y[idx] = f(i)\n",
    "\n",
    "# Normalize Data\n",
    "Y = (Y - np.min(Y))/(np.max(Y)-np.min(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these X,Y, train a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/2, f = 3.316435415830541\n",
      "Optimization restart 2/2, f = 3.316435415851991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<paramz.optimization.optimization.opt_lbfgsb at 0x126c66950>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x124e19e90>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x126b8c490>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(-1,1)\n",
    "Y = Y.reshape(-1,1)\n",
    "gp = GPy.models.GPRegression(X, Y, kernel)\n",
    "gp.optimize(messages=False)\n",
    "gp.optimize_restarts(num_restarts = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition Function\n",
    "\n",
    "We will be implementing knowledge gradient acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 10   # Number of restarts \n",
    "J = 10 # Number of replications\n",
    "T = 100  # Number of steps \n",
    "a = 4    # Step size \n",
    "\n",
    "\n",
    "# Find a x with largest KG (Algorithm 3)\n",
    "x_r = np.zeros(R)\n",
    "KG_r = np.zeros(R)\n",
    "for r in range(0, R):\n",
    "    x_r[r] = np.random.random_sample(1) # Generate random sample from solution space, in this case [0,1]\n",
    "    \n",
    "    x_t = copy.deepcopy(x_r[r])\n",
    "    for t in range(0, T):\n",
    "        # Make a copy of main GP for local use\n",
    "        gp_acquision = copy.deepcopy(gp)\n",
    "        # Estimate Stocastic Gradient (Algorithm 4)\n",
    "        G = 0.0 # Gradient\n",
    "        for j in range(0, J):\n",
    "            \n",
    "            Z = np.random.normal(0.0, 1.0)\n",
    "            # Estimate the mean, var from gp trained on previous samples for the proposed x \n",
    "            mu, var = gp_acquision.predict(x_t.reshape(-1, 1))\n",
    "            # Estimates the value of intial staring point x^r_0\n",
    "            y_np1 = mu + var * Z # y_np1 = y_{n+1}\n",
    "            \n",
    "            # Update gp with new x,y\n",
    "            temp_X = gp_acquision.X\n",
    "            temp_Y = gp_acquision.Y\n",
    "            \n",
    "            X_a = np.vstack((temp_X, x_t))\n",
    "            Y_a = np.vstack((temp_Y, y_np1))\n",
    "            # Update the data but retain the model\n",
    "            gp_acquision.set_XY(X_a, Y_a)\n",
    "            \n",
    "            # Using the updated model, find the x that maximizes mean\n",
    "            def mu_np1(x): # Estimate of mu_{n+1}, refer to Algorithm 4 for specifics\n",
    "                mu, _ = gp_acquision.predict(x.reshape(-1, 1))\n",
    "                return mu\n",
    "            x_star, mu_star, _ = spy.optimize.fmin_l_bfgs_b(mu_np1, x0=x_t, approx_grad=1, bounds=[(0.0,1.0)])\n",
    "            \n",
    "            # Compute gradient of mu_{n+1} wrt x^r keeping x_star constant\n",
    "            h = 0.01 # Preturbation to estimate gradient\n",
    "            x_h = x_t + h\n",
    "            \n",
    "            # Update GP back to n samples\n",
    "            gp_acquision.set_XY(temp_X, temp_Y)\n",
    "            mu_h, var_h = gp_acquision.predict(x_h.reshape(-1, 1))\n",
    "            y_h = mu_h + var_h * Z # y_np1 = y_{n+1}\n",
    "            \n",
    "            X_a = np.vstack((temp_X, x_h))\n",
    "            Y_a = np.vstack((temp_Y, y_h))\n",
    "            # Update the data but retain the model\n",
    "            gp_acquision.set_XY(X_a, Y_a)\n",
    "            mu_h, _ = gp_acquision.predict(x_star.reshape(-1, 1))\n",
    "            \n",
    "            G += (mu_h - mu_star)/h\n",
    "        \n",
    "        # Gradient KG\n",
    "        delta_KG = G/J\n",
    "        \n",
    "        # Update the stepsize \n",
    "        at = (a)/(a + t)\n",
    "        \n",
    "        # Update with gradient ascent\n",
    "        x_t = x_t + at * delta_KG\n",
    "    \n",
    "    x_r[r] = copy.deepcopy(x_t)\n",
    "    # Now we have found out x. Lets estimate the knowledge gain for choosing that x (Algorithm 2)\n",
    "    \n",
    "    def mu_n(x): # Estimate of mu_n, refer to Algorithm 2 for specifics\n",
    "        mu, _ = gp.predict(x.reshape(-1, 1))\n",
    "        return mu\n",
    "    \n",
    "    # Best performing x in n samples\n",
    "    _, mu_star_n, _ = spy.optimize.fmin_l_bfgs_b(mu_np1, x0=x_t, approx_grad=1, bounds=[(0.0,1.0)])\n",
    "    \n",
    "    mu, var = gp.predict(x_t.reshape(-1,1))\n",
    "    gp_kg = copy.deepcopy(gp)\n",
    "    delta_kg = 0.0\n",
    "    for j in range(0, J):\n",
    "        \n",
    "        # Predicited performance of this sampling at this x_t\n",
    "        y_np1 = np.random.normal(mu, var)\n",
    "        \n",
    "        # If sampled at this point, how the overall estimate change\n",
    "        X_kg = np.vstack((temp_X, x_t))\n",
    "        Y_kg = np.vstack((temp_Y, y_np1))\n",
    "        # Update the data but retain the model\n",
    "        gp_kg.set_XY(X_kg, Y_kg)\n",
    "        \n",
    "        def mu_np1_kg(x): # Estimate of mu_n, refer to Algorithm 2 for specifics\n",
    "            mu, _ = gp_kg.predict(x.reshape(-1, 1))\n",
    "            return mu\n",
    "    \n",
    "        # Best performing x in n samples\n",
    "        _, mu_star_np1, _ = spy.optimize.fmin_l_bfgs_b(mu_np1_kg, x0=x_t, approx_grad=1, bounds=[(0.0,1.0)])\n",
    "        \n",
    "        delta_kg += mu_star_np1 - mu_star_n\n",
    "    \n",
    "    KG_r[r] = delta_kg/J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530083280091131"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r[np.argmax(KG_r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
